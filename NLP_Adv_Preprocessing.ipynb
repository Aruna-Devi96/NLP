{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Adv Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3n9UgjheOiNz",
        "outputId": "a6e35979-c57f-47e5-82a8-a126bdc06d3b"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "\"\"\"\r\n",
        "Created on Monday Dec 23 2020\r\n",
        "@author: Aruna Devi R\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nCreated on Monday Dec 22 2020\\n@author: Aruna Devi R\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4JKyL8IOnVd",
        "outputId": "00879947-3655-43b1-cc16-1f593286aa74"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f3Hz3-OOuDy"
      },
      "source": [
        "from nltk.stem import PorterStemmer \r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzc_siS_OvRi"
      },
      "source": [
        "paragraph = \"\"\"Neuro-linguistic programming (NLP) is a psychological approach that involves analyzing strategies used by successful individuals and applying them to reach a personal goal. It relates thoughts, language, and patterns of behavior learned through experience to specific outcomes.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYeX_bxrPXxv"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLdb-9gaO1JI",
        "outputId": "b9e5bd09-b7ea-4569-af84-03d7d9d799c5"
      },
      "source": [
        "# Tokenizing sentences\r\n",
        "sentences = nltk.sent_tokenize(paragraph)\r\n",
        "print(len(sentences), sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 ['Neuro-linguistic programming (NLP) is a psychological approach that involves analyzing strategies used by successful individuals and applying them to reach a personal goal.', 'It relates thoughts, language, and patterns of behavior learned through experience to specific outcomes.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_mc63mvWeLT",
        "outputId": "57f2991e-bd82-453f-d483-9d1c4d0390e1"
      },
      "source": [
        "# Tokenizing words\r\n",
        "words = nltk.word_tokenize(paragraph)\r\n",
        "print(len(words), words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43 ['Neuro-linguistic', 'programming', '(', 'NLP', ')', 'is', 'a', 'psychological', 'approach', 'that', 'involves', 'analyzing', 'strategies', 'used', 'by', 'successful', 'individuals', 'and', 'applying', 'them', 'to', 'reach', 'a', 'personal', 'goal', '.', 'It', 'relates', 'thoughts', ',', 'language', ',', 'and', 'patterns', 'of', 'behavior', 'learned', 'through', 'experience', 'to', 'specific', 'outcomes', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvoklDaVXkgA"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AqTIAOlW6GB",
        "outputId": "1f9d952e-abee-43ea-bd61-7db183215f34"
      },
      "source": [
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IddChSlebwYT",
        "outputId": "908301ce-4b56-4f8a-840d-6a23783503eb"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Neuro-linguistic programming (NLP) is a psychological approach that involves analyzing strategies used by successful individuals and applying them to reach a personal goal.',\n",
              " 'It relates thoughts, language, and patterns of behavior learned through experience to specific outcomes.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Wva9ddXo60"
      },
      "source": [
        "stemmer = PorterStemmer()\r\n",
        "# Stemming Logic\r\n",
        "for i in range(len(sentences)):\r\n",
        "    words = nltk.word_tokenize(sentences[i])\r\n",
        "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\r\n",
        "    sentences[i] = ' '.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUefmMk6YiaA",
        "outputId": "490dee59-dedc-4075-9a83-5f0c48933c6a"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neuro-linguist program ( nlp ) psycholog approach involv analyz strategi use success individu appli reach person goal .',\n",
              " 'It relat thought , languag , pattern behavior learn experi specif outcom .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsrVWYn-auQ0"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWBwykBiYwCn",
        "outputId": "b0288962-0322-48c6-f4ac-068050053602"
      },
      "source": [
        "nltk.download('wordnet')\r\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5LHoAPycvrU"
      },
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7WBgIAka6Sy"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "# Lemmatization\r\n",
        "for i in range(len(sentences)):\r\n",
        "    words = nltk.word_tokenize(sentences[i]) # word tokenization in each sentence\r\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\r\n",
        "    sentences[i] = ' '.join(words)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-W20z3ybHla",
        "outputId": "1927bece-af58-4627-db60-0a414a528a1e"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Neuro-linguistic programming ( NLP ) psychological approach involves analyzing strategy used successful individual applying reach personal goal .',\n",
              " 'It relates thought , language , pattern behavior learned experience specific outcome .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBViMAvldBJN"
      },
      "source": [
        "### BagOfWords with Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WrVN3BbbPOJ",
        "outputId": "9a9e1981-b8d2-4340-cbeb-6b2bce3a28a0"
      },
      "source": [
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "sentences = nltk.sent_tokenize(paragraph)\r\n",
        "\r\n",
        "pstem = PorterStemmer()\r\n",
        "sentences = nltk.sent_tokenize(paragraph)\r\n",
        "corpus = []\r\n",
        "\r\n",
        "# Basic Text Pre-processing\r\n",
        "for i in range(len(sentences)):\r\n",
        "    corp = re.sub('[^a-zA-Z]', ' ', sentences[i])\r\n",
        "    corp = re.sub(r'\\[[0-9]*\\]',' ',corp)\r\n",
        "    corp = re.sub(r'\\s+',' ',corp)\r\n",
        "    corp = re.sub(r'\\d',' ',corp)\r\n",
        "    corp = corp.lower()\r\n",
        "    corp = corp.split()\r\n",
        "    corp = [pstem.stem(word) for word in corp if not word in set(stopwords.words('english'))]\r\n",
        "    corp = ' '.join(corp)\r\n",
        "    corpus.append(corp)\r\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neuro linguist program nlp psycholog approach involv analyz strategi use success individu appli reach person goal',\n",
              " 'relat thought languag pattern behavior learn experi specif outcom']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arJJIMOje3qH"
      },
      "source": [
        "# Creating the Bag of Words model\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "cv = CountVectorizer(max_features = 500)\r\n",
        "X = cv.fit_transform(corpus).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B8C5G5cd5X3",
        "outputId": "20efe911-36a3-4276-a2f3-2af62f46fcde"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "        1, 0, 1],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyF41F2FfHOT"
      },
      "source": [
        "### Term Frequency and Inverse Document Frequency(TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxxpDIkge7Ef"
      },
      "source": [
        "# Creating the TF-IDF model\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "cv = TfidfVectorizer()\r\n",
        "X = cv.fit_transform(corpus).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUEouY2hfT53",
        "outputId": "a88f2e29-4bc8-4cbb-e15a-5a95e3d626ae"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25      , 0.25      , 0.25      , 0.        , 0.        ,\n",
              "        0.25      , 0.25      , 0.25      , 0.        , 0.        ,\n",
              "        0.25      , 0.25      , 0.25      , 0.        , 0.        ,\n",
              "        0.25      , 0.25      , 0.25      , 0.25      , 0.        ,\n",
              "        0.        , 0.25      , 0.25      , 0.        , 0.25      ],\n",
              "       [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
              "        0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
              "        0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
              "        0.33333333, 0.        , 0.        , 0.33333333, 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzID8RbogjnG"
      },
      "source": [
        "### Word2Vec (Word Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TVshQ5-g5q-"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "# Preprocessing the data\r\n",
        "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\r\n",
        "text = re.sub(r'\\s+',' ',text)\r\n",
        "text = text.lower()\r\n",
        "text = re.sub(r'\\d',' ',text)\r\n",
        "text = re.sub(r'\\s+',' ',text)\r\n",
        "\r\n",
        "# Preparing the dataset\r\n",
        "sentences = nltk.sent_tokenize(text)\r\n",
        "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\r\n",
        "\r\n",
        "for i in range(len(sentences)):\r\n",
        "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h2IP-cPg8zC"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DErFM8CfUs1"
      },
      "source": [
        "from gensim.models import Word2Vec\r\n",
        "# Training the Word2Vec model\r\n",
        "model = Word2Vec(sentences, min_count=1)\r\n",
        "words = model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEygopHthCeR"
      },
      "source": [
        "vector = model.wv['approach']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_I-HnJuiIjZ",
        "outputId": "a63de48f-fdc3-496a-f087-a35514b16e0e"
      },
      "source": [
        "# Most similar words\r\n",
        "model.wv.most_similar('approach')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('neuro-linguistic', 0.2270651012659073),\n",
              " ('strategies', 0.10953246802091599),\n",
              " ('patterns', 0.09466398507356644),\n",
              " ('.', 0.09436996281147003),\n",
              " ('behavior', 0.07975082099437714),\n",
              " ('relates', 0.07506164908409119),\n",
              " ('reach', 0.06882995367050171),\n",
              " ('personal', 0.03917991369962692),\n",
              " ('analyzing', 0.033424291759729385),\n",
              " ('language', 0.0220712348818779)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPf38DlHiW6K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}